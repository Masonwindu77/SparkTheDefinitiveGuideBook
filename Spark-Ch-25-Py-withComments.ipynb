{"cells":[{"cell_type":"markdown","source":["## Chapter 25, Preprocessing and Feature Engineering\n\nCode in the book and code in github repository differ quite a lot, especially at the beginning."],"metadata":{}},{"cell_type":"markdown","source":["**Note:** I needed to change file names because I am loading them from community cloud DataBricks account. The files are the same as the ones provided in the STDG github."],"metadata":{}},{"cell_type":"code","source":["sales = spark.read.format(\"csv\")\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .load(\"/databricks-datasets/definitive-guide/data/retail-data/by-day/*.csv\")\\\n  .coalesce(5)\\\n  .where(\"Description IS NOT NULL\")\nfakeIntDF = spark.read.parquet(\"/databricks-datasets/definitive-guide/data/simple-ml-integers\")\nsimpleDF = spark.read.json(\"/databricks-datasets/definitive-guide/data/simple-ml\")\nscaleDF = spark.read.parquet(\"/databricks-datasets/definitive-guide/data/simple-ml-scaling\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["sales.cache()\nsales.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nInvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n   580538|    21914|BLUE HARMONICA IN...|      24|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n   580538|    22467|   GUMBALL COAT RACK|       6|2011-12-05 08:38:00|     2.55|   14075.0|United Kingdom|\n   580538|    21544|SKULLS  WATER TRA...|      48|2011-12-05 08:38:00|     0.85|   14075.0|United Kingdom|\n   580538|    23126|FELTCRAFT GIRL AM...|       8|2011-12-05 08:38:00|     4.95|   14075.0|United Kingdom|\n   580538|    21833|CAMOUFLAGE LED TORCH|      24|2011-12-05 08:38:00|     1.69|   14075.0|United Kingdom|\n   580539|    21479|WHITE SKULL HOT W...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n   580539|   84030E|ENGLISH ROSE HOT ...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n   580539|    23355|HOT WATER BOTTLE ...|       4|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n   580539|    22111|SCOTTIE DOG HOT W...|       3|2011-12-05 08:39:00|     4.95|   18180.0|United Kingdom|\n   580539|    21115|ROSE CARAVAN DOOR...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n   580539|    21411|GINGHAM HEART  DO...|       8|2011-12-05 08:39:00|     1.95|   18180.0|United Kingdom|\n   580539|    23235|STORAGE TIN VINTA...|      12|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n   580539|    23239|SET OF 4 KNICK KN...|       6|2011-12-05 08:39:00|     1.65|   18180.0|United Kingdom|\n   580539|    22197|      POPCORN HOLDER|      36|2011-12-05 08:39:00|     0.85|   18180.0|United Kingdom|\n   580539|    22693|GROW A FLYTRAP OR...|      24|2011-12-05 08:39:00|     1.25|   18180.0|United Kingdom|\n   580539|    22372|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n   580539|    22375|AIRLINE BAG VINTA...|       4|2011-12-05 08:39:00|     4.25|   18180.0|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer\ntkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\ntokenized = tkn.transform(sales.select(\"Description\"))\ntokenized.show(20, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------+------------------------------------------+\nDescription                        |DescOut                                   |\n+-----------------------------------+------------------------------------------+\nRABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\nDOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\nBLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\nGUMBALL COAT RACK                  |[gumball, coat, rack]                     |\nSKULLS  WATER TRANSFER TATTOOS     |[skulls, , water, transfer, tattoos]      |\nFELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\nCAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\nWHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\nENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\nHOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\nSCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\nROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\nGINGHAM HEART  DOORSTOP RED        |[gingham, heart, , doorstop, red]         |\nSTORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\nSET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\nPOPCORN HOLDER                     |[popcorn, holder]                         |\nGROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\nAIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\nAIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n+-----------------------------------+------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml.feature import StandardScaler\nsScaler = StandardScaler().setInputCol(\"features\")\nsScaler.fit(scaleDF).transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+-----------------------------------+\n id|      features|StandardScaler_d925f6abee94__output|\n+---+--------------+-----------------------------------+\n  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n  1|[3.0,10.1,3.0]|               [3.58568582800318...|\n+---+--------------+-----------------------------------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.feature import RFormula\n\nsupervised = RFormula(formula=\"lab ~ . + color:value1 + color:value2\")\nsupervised.fit(simpleDF).transform(simpleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----+------+------------------+--------------------+-----+\ncolor| lab|value1|            value2|            features|label|\n+-----+----+------+------------------+--------------------+-----+\ngreen|good|     1|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n blue| bad|     8|14.386294994851129|(10,[2,3,6,9],[8....|  0.0|\n blue| bad|    12|14.386294994851129|(10,[2,3,6,9],[12...|  0.0|\ngreen|good|    15| 38.97187133755819|(10,[1,2,3,5,8],[...|  1.0|\ngreen|good|    12|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\ngreen| bad|    16|14.386294994851129|(10,[1,2,3,5,8],[...|  0.0|\n  red|good|    35|14.386294994851129|(10,[0,2,3,4,7],[...|  1.0|\n  red| bad|     1| 38.97187133755819|(10,[0,2,3,4,7],[...|  0.0|\n  red| bad|     2|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n  red| bad|    16|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n  red|good|    45| 38.97187133755819|(10,[0,2,3,4,7],[...|  1.0|\ngreen|good|     1|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\n blue| bad|     8|14.386294994851129|(10,[2,3,6,9],[8....|  0.0|\n blue| bad|    12|14.386294994851129|(10,[2,3,6,9],[12...|  0.0|\ngreen|good|    15| 38.97187133755819|(10,[1,2,3,5,8],[...|  1.0|\ngreen|good|    12|14.386294994851129|(10,[1,2,3,5,8],[...|  1.0|\ngreen| bad|    16|14.386294994851129|(10,[1,2,3,5,8],[...|  0.0|\n  red|good|    35|14.386294994851129|(10,[0,2,3,4,7],[...|  1.0|\n  red| bad|     1| 38.97187133755819|(10,[0,2,3,4,7],[...|  0.0|\n  red| bad|     2|14.386294994851129|(10,[0,2,3,4,7],[...|  0.0|\n+-----+----+------+------------------+--------------------+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.feature import SQLTransformer\n\nbasicTransformation = SQLTransformer()\\\n  .setStatement(\"\"\"\n    SELECT sum(Quantity), count(*), CustomerID\n    FROM __THIS__\n    GROUP BY CustomerID\n  \"\"\")\n\nbasicTransformation.transform(sales).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+--------+----------+\nsum(Quantity)|count(1)|CustomerID|\n+-------------+--------+----------+\n          119|      62|   14452.0|\n          440|     143|   16916.0|\n          630|      72|   17633.0|\n           34|       6|   14768.0|\n         1542|      30|   13094.0|\n          854|     117|   17884.0|\n           97|      12|   16596.0|\n          290|      98|   13607.0|\n          541|      27|   14285.0|\n          244|      31|   16561.0|\n          491|     152|   13956.0|\n          204|      76|   13533.0|\n          493|      64|   16629.0|\n          159|      38|   17267.0|\n         1140|      30|   13918.0|\n           55|      28|   18114.0|\n           88|       7|   14473.0|\n          150|      16|   14024.0|\n          206|      23|   12493.0|\n          138|      18|   15776.0|\n+-------------+--------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nva = VectorAssembler().setInputCols([\"int1\", \"int2\", \"int3\"])\nva.transform(fakeIntDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+------------------------------------+\nint1|int2|int3|VectorAssembler_0e40691e802a__output|\n+----+----+----+------------------------------------+\n   1|   2|   3|                       [1.0,2.0,3.0]|\n   4|   5|   6|                       [4.0,5.0,6.0]|\n   7|   8|   9|                       [7.0,8.0,9.0]|\n+----+----+----+------------------------------------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["contDF = spark.range(20).selectExpr(\"cast(id as double)\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.feature import Bucketizer\nbucketBorders = [-1.0, 5.0, 10.0, 250.0, 600.0]\nbucketer = Bucketizer().setSplits(bucketBorders).setInputCol(\"id\")\nbucketer.transform(contDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-------------------------------+\n  id|Bucketizer_65ca7107f3dd__output|\n+----+-------------------------------+\n 0.0|                            0.0|\n 1.0|                            0.0|\n 2.0|                            0.0|\n 3.0|                            0.0|\n 4.0|                            0.0|\n 5.0|                            1.0|\n 6.0|                            1.0|\n 7.0|                            1.0|\n 8.0|                            1.0|\n 9.0|                            1.0|\n10.0|                            2.0|\n11.0|                            2.0|\n12.0|                            2.0|\n13.0|                            2.0|\n14.0|                            2.0|\n15.0|                            2.0|\n16.0|                            2.0|\n17.0|                            2.0|\n18.0|                            2.0|\n19.0|                            2.0|\n+----+-------------------------------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["You may note that our transformations are done in a similar manner: we import an object with transformation methods, and apply `.transform` method to our data. Although the command looks exactly the same but when utilized with different object it works differently. With `Tokenizer` object the command separates a record description into singe words, and with `Bucketizer` object we get a bucket number for each row. Below we will see that this method is preceeded by additional one, `.fit`. It is here because this time we need additional information from our data for the transformation to work: cutoff points for quantiles. The `.fit` method extracts the information. In the STDG such method is called a Spark estimator."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import QuantileDiscretizer\ndiscretizer = QuantileDiscretizer(numBuckets=5, inputCol=\"id\", outputCol ='quantiles')\nresult = discretizer.fit(contDF).transform(contDF)\nresult.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+---------+\n  id|quantiles|\n+----+---------+\n 0.0|      0.0|\n 1.0|      0.0|\n 2.0|      0.0|\n 3.0|      1.0|\n 4.0|      1.0|\n 5.0|      1.0|\n 6.0|      1.0|\n 7.0|      2.0|\n 8.0|      2.0|\n 9.0|      2.0|\n10.0|      2.0|\n11.0|      2.0|\n12.0|      3.0|\n13.0|      3.0|\n14.0|      3.0|\n15.0|      4.0|\n16.0|      4.0|\n17.0|      4.0|\n18.0|      4.0|\n19.0|      4.0|\n+----+---------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["For `StandardScaler` object we need additional information, too: a column mean and its standard deviation. \n\nThese transformations are done in 2 stages because we often need to apply the same transformation to our test set. For this our transformation object keeps the information which was derived from our data, and we can apply a required transformation with `.transform` method only. When we work with text data such approach allows to ignore new words in test set which were not in our train set. \n\nBy the way many tranfsormation objects have `.inverse_transform` method as well. Because if you transformed your output (`label`), for example, binarizing, then your predictions will be in the same format, and you will want them in the original form."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StandardScaler\nsScaler = StandardScaler().setInputCol(\"features\")\nsScaler.fit(scaleDF).transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+-----------------------------------+\n id|      features|StandardScaler_9d6525ca1a25__output|\n+---+--------------+-----------------------------------+\n  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n  1|[3.0,10.1,3.0]|               [3.58568582800318...|\n+---+--------------+-----------------------------------+\n\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["from pyspark.ml.feature import MinMaxScaler\nminMax = MinMaxScaler().setMin(5).setMax(10).setInputCol(\"features\")\nfittedminMax = minMax.fit(scaleDF)\nfittedminMax.transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+---------------------------------+\n id|      features|MinMaxScaler_3eccf3759829__output|\n+---+--------------+---------------------------------+\n  0|[1.0,0.1,-1.0]|                    [5.0,5.0,5.0]|\n  1| [2.0,1.1,1.0]|                    [7.5,5.5,7.5]|\n  0|[1.0,0.1,-1.0]|                    [5.0,5.0,5.0]|\n  1| [2.0,1.1,1.0]|                    [7.5,5.5,7.5]|\n  1|[3.0,10.1,3.0]|                 [10.0,10.0,10.0]|\n+---+--------------+---------------------------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.feature import MaxAbsScaler\nmaScaler = MaxAbsScaler().setInputCol(\"features\")\nfittedmaScaler = maScaler.fit(scaleDF)\nfittedmaScaler.transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+---------------------------------+\n id|      features|MaxAbsScaler_3d3661efba93__output|\n+---+--------------+---------------------------------+\n  0|[1.0,0.1,-1.0]|             [0.33333333333333...|\n  1| [2.0,1.1,1.0]|             [0.66666666666666...|\n  0|[1.0,0.1,-1.0]|             [0.33333333333333...|\n  1| [2.0,1.1,1.0]|             [0.66666666666666...|\n  1|[3.0,10.1,3.0]|                    [1.0,1.0,1.0]|\n+---+--------------+---------------------------------+\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.feature import ElementwiseProduct\nfrom pyspark.ml.linalg import Vectors\nscaleUpVec = Vectors.dense(10.0, 15.0, 20.0)\nscalingUp = ElementwiseProduct()\\\n  .setScalingVec(scaleUpVec)\\\n  .setInputCol(\"features\")\nscalingUp.transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+---------------------------------------+\n id|      features|ElementwiseProduct_89bc346080ea__output|\n+---+--------------+---------------------------------------+\n  0|[1.0,0.1,-1.0]|                       [10.0,1.5,-20.0]|\n  1| [2.0,1.1,1.0]|                       [20.0,16.5,20.0]|\n  0|[1.0,0.1,-1.0]|                       [10.0,1.5,-20.0]|\n  1| [2.0,1.1,1.0]|                       [20.0,16.5,20.0]|\n  1|[3.0,10.1,3.0]|                      [30.0,151.5,60.0]|\n+---+--------------+---------------------------------------+\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.feature import Normalizer\nmanhattanDistance = Normalizer().setP(1).setInputCol(\"features\")\nmanhattanDistance.transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+-------------------------------+\n id|      features|Normalizer_0052afa86191__output|\n+---+--------------+-------------------------------+\n  0|[1.0,0.1,-1.0]|           [0.47619047619047...|\n  1| [2.0,1.1,1.0]|           [0.48780487804878...|\n  0|[1.0,0.1,-1.0]|           [0.47619047619047...|\n  1| [2.0,1.1,1.0]|           [0.48780487804878...|\n  1|[3.0,10.1,3.0]|           [0.18633540372670...|\n+---+--------------+-------------------------------+\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer\nlblIndxr = StringIndexer().setInputCol(\"lab\").setOutputCol(\"labelInd\")\nidxRes = lblIndxr.fit(simpleDF).transform(simpleDF)\nidxRes.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----+------+------------------+--------+\ncolor| lab|value1|            value2|labelInd|\n+-----+----+------+------------------+--------+\ngreen|good|     1|14.386294994851129|     1.0|\n blue| bad|     8|14.386294994851129|     0.0|\n blue| bad|    12|14.386294994851129|     0.0|\ngreen|good|    15| 38.97187133755819|     1.0|\ngreen|good|    12|14.386294994851129|     1.0|\ngreen| bad|    16|14.386294994851129|     0.0|\n  red|good|    35|14.386294994851129|     1.0|\n  red| bad|     1| 38.97187133755819|     0.0|\n  red| bad|     2|14.386294994851129|     0.0|\n  red| bad|    16|14.386294994851129|     0.0|\n  red|good|    45| 38.97187133755819|     1.0|\ngreen|good|     1|14.386294994851129|     1.0|\n blue| bad|     8|14.386294994851129|     0.0|\n blue| bad|    12|14.386294994851129|     0.0|\ngreen|good|    15| 38.97187133755819|     1.0|\ngreen|good|    12|14.386294994851129|     1.0|\ngreen| bad|    16|14.386294994851129|     0.0|\n  red|good|    35|14.386294994851129|     1.0|\n  red| bad|     1| 38.97187133755819|     0.0|\n  red| bad|     2|14.386294994851129|     0.0|\n+-----+----+------+------------------+--------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["valIndexer = StringIndexer().setInputCol(\"value1\").setOutputCol(\"valueInd\")\nvalIndexer.fit(simpleDF).transform(simpleDF).show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----+------+------------------+--------+\ncolor| lab|value1|            value2|valueInd|\n+-----+----+------+------------------+--------+\ngreen|good|     1|14.386294994851129|     2.0|\n blue| bad|     8|14.386294994851129|     4.0|\n blue| bad|    12|14.386294994851129|     0.0|\ngreen|good|    15| 38.97187133755819|     5.0|\ngreen|good|    12|14.386294994851129|     0.0|\n+-----+----+------+------------------+--------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["from pyspark.ml.feature import IndexToString\nlabelReverse = IndexToString().setInputCol(\"labelInd\")\nlabelReverse.transform(idxRes).show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----+------+------------------+--------+----------------------------------+\ncolor| lab|value1|            value2|labelInd|IndexToString_0b2c36cb3fab__output|\n+-----+----+------+------------------+--------+----------------------------------+\ngreen|good|     1|14.386294994851129|     1.0|                              good|\n blue| bad|     8|14.386294994851129|     0.0|                               bad|\n blue| bad|    12|14.386294994851129|     0.0|                               bad|\ngreen|good|    15| 38.97187133755819|     1.0|                              good|\ngreen|good|    12|14.386294994851129|     1.0|                              good|\n+-----+----+------+------------------+--------+----------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["from pyspark.ml.feature import VectorIndexer\nfrom pyspark.ml.linalg import Vectors\nidxIn = spark.createDataFrame([\n  (Vectors.dense(1, 2, 3),1),\n  (Vectors.dense(2, 5, 6),2),\n  (Vectors.dense(1, 8, 9),3)\n]).toDF(\"features\", \"label\")\nindxr = VectorIndexer()\\\n  .setInputCol(\"features\")\\\n  .setOutputCol(\"idxed\")\\\n  .setMaxCategories(2)\nindxr.fit(idxIn).transform(idxIn).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+-----+-------------+\n     features|label|        idxed|\n+-------------+-----+-------------+\n[1.0,2.0,3.0]|    1|[0.0,2.0,3.0]|\n[2.0,5.0,6.0]|    2|[1.0,5.0,6.0]|\n[1.0,8.0,9.0]|    3|[0.0,8.0,9.0]|\n+-------------+-----+-------------+\n\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["from pyspark.ml.feature import OneHotEncoder, StringIndexer\nlblIndxr = StringIndexer().setInputCol(\"color\").setOutputCol(\"colorInd\")\ncolorLab = lblIndxr.fit(simpleDF).transform(simpleDF.select(\"color\"))\nohe = OneHotEncoder().setInputCol(\"colorInd\")\nohe.transform(colorLab).show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------+----------------------------------+\ncolor|colorInd|OneHotEncoder_c97639b13858__output|\n+-----+--------+----------------------------------+\ngreen|     1.0|                     (2,[1],[1.0])|\n blue|     2.0|                         (2,[],[])|\n blue|     2.0|                         (2,[],[])|\ngreen|     1.0|                     (2,[1],[1.0])|\ngreen|     1.0|                     (2,[1],[1.0])|\ngreen|     1.0|                     (2,[1],[1.0])|\n  red|     0.0|                     (2,[0],[1.0])|\n  red|     0.0|                     (2,[0],[1.0])|\n  red|     0.0|                     (2,[0],[1.0])|\n  red|     0.0|                     (2,[0],[1.0])|\n+-----+--------+----------------------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["The following cell was `RegexTokenizer` instead of `Tokenizer` as it was presented in the book."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer\ntkn = Tokenizer()\\\n  .setInputCol(\"Description\")\\\n  .setOutputCol(\"DescOut\")\ntokenized = tkn.transform(sales.select(\"Description\"))\ntokenized.show(20, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------+------------------------------------------+\nDescription                        |DescOut                                   |\n+-----------------------------------+------------------------------------------+\nRABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\nDOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\nBLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\nGUMBALL COAT RACK                  |[gumball, coat, rack]                     |\nSKULLS  WATER TRANSFER TATTOOS     |[skulls, , water, transfer, tattoos]      |\nFELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\nCAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\nWHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\nENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\nHOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\nSCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\nROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\nGINGHAM HEART  DOORSTOP RED        |[gingham, heart, , doorstop, red]         |\nSTORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\nSET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\nPOPCORN HOLDER                     |[popcorn, holder]                         |\nGROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\nAIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\nAIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n+-----------------------------------+------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["from pyspark.ml.feature import RegexTokenizer\nrt = RegexTokenizer()\\\n  .setInputCol(\"Description\")\\\n  .setOutputCol(\"DescOut\")\\\n  .setPattern(\" \")\\\n  .setToLowercase(True)\nrt.transform(sales.select(\"Description\")).show(20, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------+------------------------------------------+\nDescription                        |DescOut                                   |\n+-----------------------------------+------------------------------------------+\nRABBIT NIGHT LIGHT                 |[rabbit, night, light]                    |\nDOUGHNUT LIP GLOSS                 |[doughnut, lip, gloss]                    |\n12 MESSAGE CARDS WITH ENVELOPES    |[12, message, cards, with, envelopes]     |\nBLUE HARMONICA IN BOX              |[blue, harmonica, in, box]                |\nGUMBALL COAT RACK                  |[gumball, coat, rack]                     |\nSKULLS  WATER TRANSFER TATTOOS     |[skulls, water, transfer, tattoos]        |\nFELTCRAFT GIRL AMELIE KIT          |[feltcraft, girl, amelie, kit]            |\nCAMOUFLAGE LED TORCH               |[camouflage, led, torch]                  |\nWHITE SKULL HOT WATER BOTTLE       |[white, skull, hot, water, bottle]        |\nENGLISH ROSE HOT WATER BOTTLE      |[english, rose, hot, water, bottle]       |\nHOT WATER BOTTLE KEEP CALM         |[hot, water, bottle, keep, calm]          |\nSCOTTIE DOG HOT WATER BOTTLE       |[scottie, dog, hot, water, bottle]        |\nROSE CARAVAN DOORSTOP              |[rose, caravan, doorstop]                 |\nGINGHAM HEART  DOORSTOP RED        |[gingham, heart, doorstop, red]           |\nSTORAGE TIN VINTAGE LEAF           |[storage, tin, vintage, leaf]             |\nSET OF 4 KNICK KNACK TINS POPPIES  |[set, of, 4, knick, knack, tins, poppies] |\nPOPCORN HOLDER                     |[popcorn, holder]                         |\nGROW A FLYTRAP OR SUNFLOWER IN TIN |[grow, a, flytrap, or, sunflower, in, tin]|\nAIRLINE BAG VINTAGE WORLD CHAMPION |[airline, bag, vintage, world, champion]  |\nAIRLINE BAG VINTAGE JET SET BROWN  |[airline, bag, vintage, jet, set, brown]  |\n+-----------------------------------+------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["We see a lot of spaces in the left column, as we are supposed."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import RegexTokenizer\nrt = RegexTokenizer()\\\n  .setInputCol(\"Description\")\\\n  .setOutputCol(\"DescOut\")\\\n  .setPattern(\" \")\\\n  .setGaps(False)\\\n  .setToLowercase(True)\nrt.transform(sales.select(\"Description\")).show(20, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------+------------------+\nDescription                        |DescOut           |\n+-----------------------------------+------------------+\nRABBIT NIGHT LIGHT                 |[ ,  ]            |\nDOUGHNUT LIP GLOSS                 |[ ,  ,  ]         |\n12 MESSAGE CARDS WITH ENVELOPES    |[ ,  ,  ,  ]      |\nBLUE HARMONICA IN BOX              |[ ,  ,  ,  ]      |\nGUMBALL COAT RACK                  |[ ,  ]            |\nSKULLS  WATER TRANSFER TATTOOS     |[ ,  ,  ,  ,  ]   |\nFELTCRAFT GIRL AMELIE KIT          |[ ,  ,  ]         |\nCAMOUFLAGE LED TORCH               |[ ,  ]            |\nWHITE SKULL HOT WATER BOTTLE       |[ ,  ,  ,  ,  ]   |\nENGLISH ROSE HOT WATER BOTTLE      |[ ,  ,  ,  ]      |\nHOT WATER BOTTLE KEEP CALM         |[ ,  ,  ,  ]      |\nSCOTTIE DOG HOT WATER BOTTLE       |[ ,  ,  ,  ]      |\nROSE CARAVAN DOORSTOP              |[ ,  ]            |\nGINGHAM HEART  DOORSTOP RED        |[ ,  ,  ,  ]      |\nSTORAGE TIN VINTAGE LEAF           |[ ,  ,  ]         |\nSET OF 4 KNICK KNACK TINS POPPIES  |[ ,  ,  ,  ,  ,  ]|\nPOPCORN HOLDER                     |[ ]               |\nGROW A FLYTRAP OR SUNFLOWER IN TIN |[ ,  ,  ,  ,  ,  ]|\nAIRLINE BAG VINTAGE WORLD CHAMPION |[ ,  ,  ,  ,  ]   |\nAIRLINE BAG VINTAGE JET SET BROWN  |[ ,  ,  ,  ,  ]   |\n+-----------------------------------+------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["from pyspark.ml.feature import StopWordsRemover\nenglishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\nstops = StopWordsRemover()\\\n  .setStopWords(englishStopWords)\\\n  .setInputCol(\"DescOut\")\nstops.transform(tokenized).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+-------------------------------------+\n         Description|             DescOut|StopWordsRemover_b487699f1da6__output|\n+--------------------+--------------------+-------------------------------------+\n  RABBIT NIGHT LIGHT|[rabbit, night, l...|                 [rabbit, night, l...|\n DOUGHNUT LIP GLOSS |[doughnut, lip, g...|                 [doughnut, lip, g...|\n12 MESSAGE CARDS ...|[12, message, car...|                 [12, message, car...|\nBLUE HARMONICA IN...|[blue, harmonica,...|                 [blue, harmonica,...|\n   GUMBALL COAT RACK|[gumball, coat, r...|                 [gumball, coat, r...|\nSKULLS  WATER TRA...|[skulls, , water,...|                 [skulls, , water,...|\nFELTCRAFT GIRL AM...|[feltcraft, girl,...|                 [feltcraft, girl,...|\nCAMOUFLAGE LED TORCH|[camouflage, led,...|                 [camouflage, led,...|\nWHITE SKULL HOT W...|[white, skull, ho...|                 [white, skull, ho...|\nENGLISH ROSE HOT ...|[english, rose, h...|                 [english, rose, h...|\nHOT WATER BOTTLE ...|[hot, water, bott...|                 [hot, water, bott...|\nSCOTTIE DOG HOT W...|[scottie, dog, ho...|                 [scottie, dog, ho...|\nROSE CARAVAN DOOR...|[rose, caravan, d...|                 [rose, caravan, d...|\nGINGHAM HEART  DO...|[gingham, heart, ...|                 [gingham, heart, ...|\nSTORAGE TIN VINTA...|[storage, tin, vi...|                 [storage, tin, vi...|\nSET OF 4 KNICK KN...|[set, of, 4, knic...|                 [set, 4, knick, k...|\n      POPCORN HOLDER|   [popcorn, holder]|                    [popcorn, holder]|\nGROW A FLYTRAP OR...|[grow, a, flytrap...|                 [grow, flytrap, s...|\nAIRLINE BAG VINTA...|[airline, bag, vi...|                 [airline, bag, vi...|\nAIRLINE BAG VINTA...|[airline, bag, vi...|                 [airline, bag, vi...|\n+--------------------+--------------------+-------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["The `NGram` method did not work. Maybe it was depreciated. I looked up its documentation to fix it."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import NGram\nunigram = NGram(n=1, inputCol=\"DescOut\", outputCol=\"unigrams\")\nunigramDataFrame = unigram.transform(tokenized)\nunigramDataFrame.select(\"unigrams\").show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------+\nunigrams                                  |\n+------------------------------------------+\n[rabbit, night, light]                    |\n[doughnut, lip, gloss]                    |\n[12, message, cards, with, envelopes]     |\n[blue, harmonica, in, box]                |\n[gumball, coat, rack]                     |\n[skulls, , water, transfer, tattoos]      |\n[feltcraft, girl, amelie, kit]            |\n[camouflage, led, torch]                  |\n[white, skull, hot, water, bottle]        |\n[english, rose, hot, water, bottle]       |\n[hot, water, bottle, keep, calm]          |\n[scottie, dog, hot, water, bottle]        |\n[rose, caravan, doorstop]                 |\n[gingham, heart, , doorstop, red]         |\n[storage, tin, vintage, leaf]             |\n[set, of, 4, knick, knack, tins, poppies] |\n[popcorn, holder]                         |\n[grow, a, flytrap, or, sunflower, in, tin]|\n[airline, bag, vintage, world, champion]  |\n[airline, bag, vintage, jet, set, brown]  |\n+------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["bigram = NGram(n=2, inputCol=\"DescOut\", outputCol=\"bigrams\")\nbigramDataFrame = bigram.transform(tokenized)\nbigramDataFrame.select(\"bigrams\").show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------------------------------------------+\nbigrams                                                            |\n+-------------------------------------------------------------------+\n[rabbit night, night light]                                        |\n[doughnut lip, lip gloss]                                          |\n[12 message, message cards, cards with, with envelopes]            |\n[blue harmonica, harmonica in, in box]                             |\n[gumball coat, coat rack]                                          |\n[skulls ,  water, water transfer, transfer tattoos]                |\n[feltcraft girl, girl amelie, amelie kit]                          |\n[camouflage led, led torch]                                        |\n[white skull, skull hot, hot water, water bottle]                  |\n[english rose, rose hot, hot water, water bottle]                  |\n[hot water, water bottle, bottle keep, keep calm]                  |\n[scottie dog, dog hot, hot water, water bottle]                    |\n[rose caravan, caravan doorstop]                                   |\n[gingham heart, heart ,  doorstop, doorstop red]                   |\n[storage tin, tin vintage, vintage leaf]                           |\n[set of, of 4, 4 knick, knick knack, knack tins, tins poppies]     |\n[popcorn holder]                                                   |\n[grow a, a flytrap, flytrap or, or sunflower, sunflower in, in tin]|\n[airline bag, bag vintage, vintage world, world champion]          |\n[airline bag, bag vintage, vintage jet, jet set, set brown]        |\n+-------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["Here the `CountVectorizer.fit` makes a frequency table for all words, takes the first 500 the most frequent, and creates a table for the word frequencies for each row. This is a truly sparse table. All 500 words are kept in `CountVectorizer` object, so a similar transformation can be applied to a test set and the resulting table will have the same columns for the same words."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import CountVectorizer\ncv = CountVectorizer(inputCol = \"DescOut\", outputCol = \"countVec\", vocabSize = 500, minDF=2.0, minTF =1.0)\nfittedCV = cv.fit(tokenized)\nresult = fittedCV.transform(tokenized)\nresult.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+\n         Description|             DescOut|            countVec|\n+--------------------+--------------------+--------------------+\n  RABBIT NIGHT LIGHT|[rabbit, night, l...|(500,[150,185,212...|\n DOUGHNUT LIP GLOSS |[doughnut, lip, g...|(500,[462,463,492...|\n12 MESSAGE CARDS ...|[12, message, car...|(500,[35,41,166],...|\nBLUE HARMONICA IN...|[blue, harmonica,...|(500,[10,16,36,35...|\n   GUMBALL COAT RACK|[gumball, coat, r...|(500,[228,280,408...|\nSKULLS  WATER TRA...|[skulls, , water,...|(500,[11,40,133],...|\nFELTCRAFT GIRL AM...|[feltcraft, girl,...|(500,[60,64,69],[...|\nCAMOUFLAGE LED TORCH|[camouflage, led,...|   (500,[264],[1.0])|\nWHITE SKULL HOT W...|[white, skull, ho...|(500,[15,34,39,40...|\nENGLISH ROSE HOT ...|[english, rose, h...|(500,[34,39,40,46...|\nHOT WATER BOTTLE ...|[hot, water, bott...|(500,[34,39,40,14...|\nSCOTTIE DOG HOT W...|[scottie, dog, ho...|(500,[34,39,40,14...|\nROSE CARAVAN DOOR...|[rose, caravan, d...|(500,[46,297],[1....|\nGINGHAM HEART  DO...|[gingham, heart, ...|(500,[3,4,11,143,...|\nSTORAGE TIN VINTA...|[storage, tin, vi...|(500,[6,45,109,16...|\nSET OF 4 KNICK KN...|[set, of, 4, knic...|(500,[0,1,49,70,3...|\n      POPCORN HOLDER|   [popcorn, holder]|(500,[21,296],[1....|\nGROW A FLYTRAP OR...|[grow, a, flytrap...|(500,[36,45,378],...|\nAIRLINE BAG VINTA...|[airline, bag, vi...|(500,[2,6,328],[1...|\nAIRLINE BAG VINTA...|[airline, bag, vi...|(500,[0,2,6,328,4...|\n+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["tfIdfIn = tokenized\\\n  .where(\"array_contains(DescOut, 'red')\")\\\n  .select(\"DescOut\")\\\n  .limit(10)\ntfIdfIn.show(10, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------+\nDescOut                                |\n+---------------------------------------+\n[gingham, heart, , doorstop, red]      |\n[red, floral, feltcraft, shoulder, bag]|\n[alarm, clock, bakelike, red]          |\n[pin, cushion, babushka, red]          |\n[red, retrospot, mini, cases]          |\n[red, kitchen, scales]                 |\n[gingham, heart, , doorstop, red]      |\n[large, red, babushka, notebook]       |\n[red, retrospot, oven, glove]          |\n[red, retrospot, plate]                |\n+---------------------------------------+\n\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF\ntf = HashingTF()\\\n  .setInputCol(\"DescOut\")\\\n  .setOutputCol(\"TFOut\")\\\n  .setNumFeatures(10000)\nidf = IDF()\\\n  .setInputCol(\"TFOut\")\\\n  .setOutputCol(\"IDFOut\")\\\n  .setMinDocFreq(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"code","source":["idf.fit(tf.transform(tfIdfIn)).transform(tf.transform(tfIdfIn)).show(10, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------+--------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------+\nDescOut                                |TFOut                                                   |IDFOut                                                                                                              |\n+---------------------------------------+--------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------+\n[gingham, heart, , doorstop, red]      |(10000,[3372,4291,4370,6594,9160],[1.0,1.0,1.0,1.0,1.0])|(10000,[3372,4291,4370,6594,9160],[1.2992829841302609,0.0,1.2992829841302609,1.2992829841302609,1.2992829841302609])|\n[red, floral, feltcraft, shoulder, bag]|(10000,[155,1152,4291,5981,6756],[1.0,1.0,1.0,1.0,1.0]) |(10000,[155,1152,4291,5981,6756],[0.0,0.0,0.0,0.0,0.0])                                                             |\n[alarm, clock, bakelike, red]          |(10000,[4291,4852,4995,9668],[1.0,1.0,1.0,1.0])         |(10000,[4291,4852,4995,9668],[0.0,0.0,0.0,0.0])                                                                     |\n[pin, cushion, babushka, red]          |(10000,[4291,5111,5673,7153],[1.0,1.0,1.0,1.0])         |(10000,[4291,5111,5673,7153],[0.0,0.0,0.0,1.2992829841302609])                                                      |\n[red, retrospot, mini, cases]          |(10000,[547,1576,2591,4291],[1.0,1.0,1.0,1.0])          |(10000,[547,1576,2591,4291],[0.0,0.0,1.0116009116784799,0.0])                                                       |\n[red, kitchen, scales]                 |(10000,[3461,4291,6214],[1.0,1.0,1.0])                  |(10000,[3461,4291,6214],[0.0,0.0,0.0])                                                                              |\n[gingham, heart, , doorstop, red]      |(10000,[3372,4291,4370,6594,9160],[1.0,1.0,1.0,1.0,1.0])|(10000,[3372,4291,4370,6594,9160],[1.2992829841302609,0.0,1.2992829841302609,1.2992829841302609,1.2992829841302609])|\n[large, red, babushka, notebook]       |(10000,[2782,2787,4291,7153],[1.0,1.0,1.0,1.0])         |(10000,[2782,2787,4291,7153],[0.0,0.0,0.0,1.2992829841302609])                                                      |\n[red, retrospot, oven, glove]          |(10000,[302,2591,4291,8242],[1.0,1.0,1.0,1.0])          |(10000,[302,2591,4291,8242],[0.0,1.0116009116784799,0.0,0.0])                                                       |\n[red, retrospot, plate]                |(10000,[2591,4291,4456],[1.0,1.0,1.0])                  |(10000,[2591,4291,4456],[1.0116009116784799,0.0,0.0])                                                               |\n+---------------------------------------+--------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["from pyspark.ml.feature import Word2Vec\n# Input data: Each row is a bag of words from a sentence or document.\ndocumentDF = spark.createDataFrame([\n    (\"Hi I heard about Spark\".split(\" \"), ),\n    (\"I wish Java could use case classes\".split(\" \"), ),\n    (\"Logistic regression models are neat\".split(\" \"), )\n], [\"text\"])\n# Learn a mapping from words to Vectors.\nword2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\",\n  outputCol=\"result\")\nmodel = word2Vec.fit(documentDF)\nresult = model.transform(documentDF)\nfor row in result.collect():\n    text, vector = row\n    print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Text: [Hi, I, heard, about, Spark] =&gt; \nVector: [0.000364033132792,-0.0473175618798,-0.0372836232185]\n\nText: [I, wish, Java, could, use, case, classes] =&gt; \nVector: [-0.0449876114726,0.0245432928205,-0.04744969947]\n\nText: [Logistic, regression, models, are, neat] =&gt; \nVector: [-0.0543659523129,-0.000254406034946,-0.0141884714365]\n\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["from pyspark.ml.feature import PCA\npca = PCA().setInputCol(\"features\").setK(2)\npca.fit(scaleDF).transform(scaleDF).show(20, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+------------------------------------------+\nid |features      |PCA_17af88c4c849__output                  |\n+---+--------------+------------------------------------------+\n0  |[1.0,0.1,-1.0]|[0.0713719499248418,-0.4526654888147822]  |\n1  |[2.0,1.1,1.0] |[-1.680494698407372,1.259340132221917]    |\n0  |[1.0,0.1,-1.0]|[0.0713719499248418,-0.4526654888147822]  |\n1  |[2.0,1.1,1.0] |[-1.680494698407372,1.259340132221917]    |\n1  |[3.0,10.1,3.0]|[-10.872398139848944,0.030962697060150646]|\n+---+--------------+------------------------------------------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["from pyspark.ml.feature import PolynomialExpansion\npe = PolynomialExpansion().setInputCol(\"features\").setDegree(2).setOutputCol(\"polyFeatures\")\npe.transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+--------------------+\n id|      features|        polyFeatures|\n+---+--------------+--------------------+\n  0|[1.0,0.1,-1.0]|[1.0,1.0,0.1,0.1,...|\n  1| [2.0,1.1,1.0]|[2.0,4.0,1.1,2.2,...|\n  0|[1.0,0.1,-1.0]|[1.0,1.0,0.1,0.1,...|\n  1| [2.0,1.1,1.0]|[2.0,4.0,1.1,2.2,...|\n  1|[3.0,10.1,3.0]|[3.0,9.0,10.1,30....|\n+---+--------------+--------------------+\n\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["from pyspark.ml.feature import ChiSqSelector, Tokenizer\ntkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\ntokenized = tkn\\\n  .transform(sales.select(\"Description\", \"CustomerId\"))\\\n  .where(\"CustomerId IS NOT NULL\")\nprechi = fittedCV.transform(tokenized)\\\n  .where(\"CustomerId IS NOT NULL\")\nchisq = ChiSqSelector()\\\n  .setFeaturesCol(\"countVec\")\\\n  .setLabelCol(\"CustomerId\")\\\n  .setNumTopFeatures(2)\nchisq.fit(prechi).transform(prechi)\\\n  .drop(\"customerId\", \"Description\", \"DescOut\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+----------------------------------+\n            countVec|ChiSqSelector_a518b9236476__output|\n+--------------------+----------------------------------+\n(500,[150,185,212...|                         (2,[],[])|\n(500,[462,463,492...|                         (2,[],[])|\n(500,[35,41,166],...|                         (2,[],[])|\n(500,[10,16,36,35...|                         (2,[],[])|\n(500,[228,280,408...|                         (2,[],[])|\n(500,[11,40,133],...|                         (2,[],[])|\n(500,[60,64,69],[...|                         (2,[],[])|\n   (500,[264],[1.0])|                         (2,[],[])|\n(500,[15,34,39,40...|                         (2,[],[])|\n(500,[34,39,40,46...|                         (2,[],[])|\n(500,[34,39,40,14...|                         (2,[],[])|\n(500,[34,39,40,14...|                         (2,[],[])|\n(500,[46,297],[1....|                         (2,[],[])|\n(500,[3,4,11,143,...|                         (2,[],[])|\n(500,[6,45,109,16...|                         (2,[],[])|\n(500,[0,1,49,70,3...|               (2,[0,1],[1.0,1.0])|\n(500,[21,296],[1....|                         (2,[],[])|\n(500,[36,45,378],...|                         (2,[],[])|\n(500,[2,6,328],[1...|                         (2,[],[])|\n(500,[0,2,6,328,4...|                     (2,[0],[1.0])|\n+--------------------+----------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["fittedPCA = pca.fit(scaleDF)\nfittedPCA.write().overwrite().save(\"/tmp/fittedPCA\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["from pyspark.ml.feature import PCAModel\nloadedPCA = PCAModel.load(\"/tmp/fittedPCA\")\nloadedPCA.transform(scaleDF).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------+------------------------+\n id|      features|PCA_17af88c4c849__output|\n+---+--------------+------------------------+\n  0|[1.0,0.1,-1.0]|    [0.07137194992484...|\n  1| [2.0,1.1,1.0]|    [-1.6804946984073...|\n  0|[1.0,0.1,-1.0]|    [0.07137194992484...|\n  1| [2.0,1.1,1.0]|    [-1.6804946984073...|\n  1|[3.0,10.1,3.0]|    [-10.872398139848...|\n+---+--------------+------------------------+\n\n</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["At the end of the chapter we can see a custom transformer in Scala but not in Python."],"metadata":{}}],"metadata":{"name":"Spark-Ch-25-Py-withComments","notebookId":1295341335623841},"nbformat":4,"nbformat_minor":0}
